# Likelihood computation in ADDM.jl

In the [previous tutorial](https://addm-toolbox.github.io/ADDM.jl/dev/tutorials/01_getting_started/) we were not able to recover the true parameters used for the simulated data when using `stateStep = 0.1`. Reducing this to `stateStep = 0.01` corrected the recovery. In this tutorial we will walk through how parameter estimation in ADDM.jl works to explain the effect of this change.

## Overview of parameter estimation steps for sequential sampling models

Regardless of the type of cognitive computational model, the way we estimate the "best" parameters begins with selecting a measure to quantify the difference between observed data and data that would be generated by the hypothesized model given a specific set of parameter values. When estimating coefficients in a linear regression, for example, we choose the sum of squared differences between the observed and predicted data. The estimated parameters are those that minimize this difference (given constraints on the parameter search space) and yield predicted data most similar to the observed data.   

For sequential sampling models like the attentional drift diffusion model, the metric of similarity between observed and predicted data needs to account for both the observed choices and response times. One can, for example, choose to match the moments of response time distributions conditioned on the choice (e.g. percentiles of the RT distribution for correct vs incorrect responses). Another metric one could choose is likelihood. In the context of sequential sampling models, the likelihood is the probability of observing the endorsed choice *at the observed response time*. This second part is what makes these models powerful. This is what we mean by the *joint* modeling of choice and response times. 

Some methods to compute likelihoods of a single observed datapoint for sequential sampling methods are:  

1. The analytical solution of the Wiener First Passage Time distribution (WFTP): This method relies on an approximation developed by Navarro and Fuss (2009) to compute an infinite integral. As it is a single equation that yields the likelihood value for a given combination of parameters it is very fast. Unfortunately, it is not flexible as the equation only applies to a single type of a drift diffusion model. The original version of the HDDM was built around this approach.  
2. Trialwise simulations: This method is not limited to likelihood computations but can be used to compute any metric of similarity between observed and hypothesized data. It relies on simulating a large number of trials to obtain an expected distribution and then comparing the observed data to this distribution for each trial. Though it can be extremely flexible it is also often unfeasibly slow. ChaRTr is one example package that implements it.  
3. Likelihood approximation networks (LANs): This relies on training neural networks to learn a function akin to a likelihood function that captures the probability of observing a choice and response time for a combination of parameters. While it can be very flexible it requires an understanding of how to work with neural networks and might be slow depending on the number of trials needed to train them. This is implemented in the newer version of the HDDM package, HSSM.  
4. Solving the Fokker Planck Equation (FPE): This relies on conceptualizing the relative decision value, the putative construct that accummulates towards a boundary to indicate a choice, as a probabilistic particle that moves in space and time. Briefly, the FPE describes how a probability distribution changes over time. Since it is an expression of change, formally it is written as a partial differential equation. We'll skip the details of the math here but for an in depth dive, please see Shinn et al.[^1].
In addition to this toolbox[^2], the pyDDM package makes use of it as well.  

Importantly, all of these methods compute the likelihood for a single observation. To choose the parameter combination that is the most similar to the data we need to take into account the likelihood of *all* observations. If we assume that each observation is independent from each other (i.e. that the decision-making process is the same in each trial) then the likelihood of all the observations would be the product of the likelihoods for each trial (like the probability of getting 3 heads in 5 coin flips). Since probabilities range from 0 to 1, this multiplication can create numerical challenges when working with computers (very small numbers). Therefore, raw likelihood values are converted to negative log likelihoods. Conveniently, maximizing the likelihoods is equivalent to minimizing negative log likelihoods. So the parameter combination that yields the smallest sum of negative log likelihoods is called the "maximum likelihood estimate" (MLE).

Likelihood-based (maximum likelihood) estimation is used in many different applications. Therefore there are many methods developed to determine how to search the parameter space to find the MLE. These are called optimization algorithms. Both built-in and custom likelihood functions in ADDM.jl can be used with various optimization algorithms (detailed [here](https://addm-toolbox.github.io/ADDM.jl/dev/tutorials/07_alt_optimization_algs/)). The built-in algorithm within ADDM.jl, grid computation, is perhaps the simplest. It requires the parameter space to be determined in advance, computes negative log likelihoods for each parameter combination and selects the combination that minimizes this. It is not the most computationally efficient method, instead we rely on Julia for speed, but one that gives researchers full control over their parameter space.

To summarize, parameter estimation for sequential sampling models involves three main steps:  

1. select evaluation metric: likelihood, conditional RT quantiles etc.
2. select method to compute metric: analytical solution, LAN, FPE etc.
3. select algorthm to explore parameter space using the evaluation metric: grid computation, gradient descent etc.

With this context, we will focus on how step 2, the computation of a single observation's likelihood, is implemented within ADDM.jl to understand the effect of `stateStep` argument.

## Likelihood of a single trial

Let's start with a simple example. We'll use a simplified classic DDM (not attentional) to illustrate the main points. Similar to the previous tutorial, first we'll define a model a simulate a single trial using it.

```@repl 2
using ADDM, CSV, DataFrames, DataFramesMeta
using Distributions, Plots, StatsPlots, Random, Plots.PlotMeasures
Random.seed!(38435)

m = ADDM.define_model(d = 0.007, σ = 0.03, barrier = 1, 
                       decay = 0, nonDecisionTime = 100, bias = 0.0);

t = ADDM.DDM_simulate_trial(model = m, valueLeft = 2, valueRight = 1.5)
```

Then we'll define a second model, one that has a larger `σ` and compare the likelihood of observing the simulated trial for both models.

```@repl 2
m2 = ADDM.define_model(d = 0.007, σ = 0.05, barrier = 1, 
                       decay = 0, nonDecisionTime = 100, bias = 0.0);

ADDM.DDM_get_trial_likelihood(model = m2, trial = t, stateStep = .1) > ADDM.DDM_get_trial_likelihood(model = m, trial = t, stateStep = .1)
```

```@repl 2
ADDM.DDM_get_trial_likelihood(model = m2, trial = t, stateStep = .01) > ADDM.DDM_get_trial_likelihood(model = m, trial = t, stateStep = .01)
```

As in the previous tutorial, we find that the incorrect model has a larger likelihood than the correct model when computing the likelihood using a `stateStep` of .1 instead of .01.

Since the trial is simulated we can examine the evolution of the relative decision variable (RDV). This is not necessary (nor is it possible with empirical data) but is intended to develop intuitions.

```@repl 2
# Draw background once keeps the trace.
plot(legend = false, grid = false, ylims = [-1, 1], xlims = [0, t.RT], xlabel = "Time (ms)")
hline!([-1, 1], line = (:black, 5))
hline!([0], line = (:gray, 1))
vline!([m.nonDecisionTime], line = (:gray, 1), linestyle = :dash)

# @gif for i in 1:length(t.RDV)
#   # If you don't want the trace include the plot background in the loop
#   plot!([i*10], [t.RDV[i]], marker = 4, color = :blue, msa = 0.)
# end

a = Animation()
	
for i in 1:length(t.RDV)
    plt = plot!([i*10], [t.RDV[i]], marker = 4, color = :blue, msa = 0.)
    frame(a, plt)
end
	
gif(a)
```


```

!!! note

    Choice is coded as `-1` but the animation is showing the RDV hit the top boundary denoted as 1.  This is a strange custom based on the analytical solution of the WFTP where the left choice is denoted as -1. The top boundary is coded as 1 and corresponds to the left choice although the `.choice` property of `ADDM.Trial` is -1.



```@repl 2
plot(legend = false, grid = false, ylims = [-1, 1], xlims = [0, t.RT], xlabel = "Time (ms)", title = "State step = .1")
hline!([-1, 1], line = (:black, 5))
hline!([0], line = (:gray, 1))
vline!([m.nonDecisionTime], line = (:gray, 1), linestyle = :dash)
vline!([1:100:t.RT], line = (:green, 1))
hline!([-1:.1:1], line = (:green, 1))
i = 11
plot!([i*10], [t.RDV[i]], marker = 4, color = :blue, msa = 0.)


plot(legend = false, grid = false, ylims = [-1, 1], xlims = [0, t.RT], xlabel = "Time (ms)", title = "State step = .01")
hline!([-1, 1], line = (:black, 5))
hline!([0], line = (:gray, 1))
vline!([m.nonDecisionTime], line = (:gray, 1), linestyle = :dash)
vline!([1:100:t.RT], line = (:green, 1))
hline!([-1:.01:1], line = (:green, 1))


plot(Normal(m.d,m.σ), legend = false, grid = false, showaxis = :x)
vline!([m.d], line = (:gray, 1), linestyle = :dash)

# Specify layout
l = @layout [a b]
p = plot(layout = l)
# Background 1
plot!(p[1], legend = false, grid = false, ylims = [-1, 1], xlims = [0, t.RT], xlabel = "Time (ms)")
hline!(p[1], [-1, 1], line = (:black, 5))
hline!(p[1], [0], line = (:gray, 1))
vline!(p[1], [m.nonDecisionTime], line = (:gray, 1), linestyle = :dash)
# Background 2
plot!(p[2], Normal(m.d,m.σ), legend = false, grid = false, showaxis = :x, color = :black)
vline!(p[2], [m.d], line = (:gray, 1), linestyle = :dash)

@gif for i in 1:length(t.RDV)
  # l = @layout [a b]
  # p = plot(layout = l)
  # # Background 1
  # plot!(p[1], legend = false, grid = false, ylims = [-1, 1], xlims = [0, t.RT], xlabel = "Time (ms)")
  # hline!(p[1], [-1, 1], line = (:black, 5))
  # hline!(p[1], [0], line = (:gray, 1))
  # vline!(p[1], [m.nonDecisionTime], line = (:gray, 1), linestyle = :dash)
  plot!(p[1], [i*10], [t.RDV[i]], marker = 4, color = :blue, msa = 0.)
  if i == 1
    samp = t.RDV[i]
  else
    samp = t.RDV[i] - t.RDV[i-1]
  end
  # plot!(p[2], Normal(m.d, m.σ), legend = false, grid = false, showaxis = :x, color = :black)
  # vline!(p[2], [m.d], line = (:gray, 1), linestyle = :dash)
  # vline!(p[2], [samp], line = (:blue, 1))
  vline!(p[2], [samp], line = (:blue, 1), linealpha = 0.0)
end

```

## The problem in the previous tutorial

Ok so what is the effect of the discretization step sizes (in both time and space)

```@repl 2
Random.seed!(38435)

MyModel = ADDM.define_model(d = 0.007, σ = 0.03, θ = .6, barrier = 1, 
                       decay = 0, nonDecisionTime = 100, bias = 0.0)

data_path = joinpath(dirname(dirname(pathof(ADDM))), "data/") # hide
data = ADDM.load_data_from_csv(data_path * "stimdata.csv", data_path * "fixations.csv"; stimsOnly = true);

nTrials = 1400;

MyStims = (valueLeft = reduce(vcat, [[i.valueLeft for i in data[j]] for j in keys(data)])[1:nTrials], valueRight = reduce(vcat, [[i.valueRight for i in data[j]] for j in keys(data)])[1:nTrials]);

vDiffs = sort(unique([x.valueLeft - x.valueRight for x in data["1"]]));

MyFixationData = ADDM.process_fixations(data, fixDistType="fixation", valueDiffs = vDiffs);

MyArgs = (timeStep = 10.0, cutOff = 20000, fixationData = MyFixationData);

SimData = ADDM.simulate_data(MyModel, MyStims, ADDM.aDDM_simulate_trial, MyArgs);
```

We can look at a few things. 

Save intermediate likelihoods for all trials with stepSize = .1 vs .01 for the correct and incorrect parameters

```@repl 2
param_grid = [(d = 0.007, sigma = 0.03, theta = 0.6), (d = 0.007, sigma = 0.05, theta = 0.6)];

output_large = ADDM.grid_search(SimData, param_grid, ADDM.aDDM_get_trial_likelihood, Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>100, :bias=>0.0), likelihood_args = (timeStep = 10.0, stateStep = 0.1), save_intermediate_likelihoods = true , intermediate_likelihood_path="./outputs/", intermediate_likelihood_fn="large_stateStep_likelihoods");

output_small = ADDM.grid_search(SimData, param_grid, ADDM.aDDM_get_trial_likelihood, Dict(:η=>0.0, :barrier=>1, :decay=>0, :nonDecisionTime=>100, :bias=>0.0), likelihood_args = (timeStep = 10.0, stateStep = 0.01), save_intermediate_likelihoods = true, intermediate_likelihood_path="./outputs/", intermediate_likelihood_fn="small_stateStep_likelihoods");
```


```@repl 2
fns = ["large", "small"];

trial_likelihoods_for_sigmas = DataFrame();
for fn in fns
  trial_likelihoods = DataFrame(CSV.File("./outputs/"* fn *"_stateStep_likelihoods.csv", delim=","))
  cur_tlfs = unstack(trial_likelihoods, :trial_num, :sigma, :likelihood)
  cur_tlfs[!, :stateStep] .= fn * " stateStep"
  trial_likelihoods_for_sigmas = vcat(trial_likelihoods_for_sigmas, cur_tlfs)
end
rename!(trial_likelihoods_for_sigmas, [Symbol(0.05), Symbol(0.03)]  .=> [:incorrect_sigma, :correct_sigma])

ax_lims = (minimum(vcat(trial_likelihoods_for_sigmas.incorrect_sigma, trial_likelihoods_for_sigmas.correct_sigma)), maximum(vcat(trial_likelihoods_for_sigmas.incorrect_sigma, trial_likelihoods_for_sigmas.correct_sigma)))

@df trial_likelihoods_for_sigmas scatter(:correct_sigma, :incorrect_sigma,
                                          xlabel = "Likelihoods for true parameters", 
                                          ylabel = "Likelihoods for incorrect parameters", 
                                          lim = ax_lims,
                                          group = :stateStep,
                                          m = (0.5, [:x :+], 4))
Plots.abline!(1, 0, line=:dash, color=:black, label="")

```

Pick a few trials where the likelihoods differ a lot between the correct and incorrect parameters. Use the debug option in the `aDDM_get_trial_likelihood` to plot the propogation of the probability distribution across timeSteps

```@repl 2
# make new column for the difference in likelihoods for correct vs incorrect sigma 
@transform!(trial_likelihoods_for_sigmas, :diff_likelihood = :incorrect_sigma - :correct_sigma)

# order by that difference column
@orderby(trial_likelihoods_for_sigmas, -:diff_likelihood)

# Pick top 4 trials (or maybe just one)
diff_trial_nums = [@orderby(trial_likelihoods_for_sigmas, -:diff_likelihood)[1,:trial_num]];

# extract these from the data
diff_trials = SimData[diff_trial_nums];
```

Plot probStates for each trial with small vs large stateStep for correct and incorrect model

```@repl 2
# 2 x 2 plot
# Rows are stepsize
# Cols are models
# Point is to show that likelihood value changes depending on stepsize
# Colors must match across the four plots
# Need a legend common to all
# Why are the prStates plots with small stepsize so dark?
# Because the values in each bin are very small. 
# They values in each bin are small because they are spread over 10 times as many bins.

correct_model = MyModel
incorrect_model = ADDM.define_model(d = 0.007, σ = 0.05, θ = .6, barrier = 1, 
                decay = 0, nonDecisionTime = 100, bias = 0.0)


# Use aDDM_get_trial_likelihood with debug = true to get probStates and probUp and 
_, prStates_cm_ls, probUpCrossing_cm_ls, probDownCrossing_cm_ls = ADDM.aDDM_get_trial_likelihood(;model = correct_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.1, debug = true)

_, prStates_cm_ss, probUpCrossing_cm_ss, probDownCrossing_cm_ss = ADDM.aDDM_get_trial_likelihood(;model = correct_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.01, debug = true)

_, prStates_im_ls, probUpCrossing_im_ls, probDownCrossing_im_ls = ADDM.aDDM_get_trial_likelihood(;model = incorrect_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.1, debug = true)

_, prStates_im_ss, probUpCrossing_im_ss, probDownCrossing_im_ss = ADDM.aDDM_get_trial_likelihood(;model = incorrect_model, trial = diff_trials[1], timeStep = 10.0, stateStep = 0.01, debug = true)

likMax = maximum(vcat(probUpCrossing_cm_ls, probDownCrossing_cm_ls, probUpCrossing_cm_ss, probDownCrossing_cm_ss, probUpCrossing_im_ls, probDownCrossing_im_ls, probUpCrossing_im_ss, probDownCrossing_im_ss))
likelihoodLims = (0, likMax);
prStateLims = (0, 0.05);

p1 = state_space_plot(prStates_cm_ls, probUpCrossing_cm_ls, probDownCrossing_cm_ls, 10, 0.1, likelihoodLims, prStateLims);
p2 = state_space_plot(prStates_cm_ss, probUpCrossing_cm_ss, probDownCrossing_cm_ss, 10, 0.01, likelihoodLims, prStateLims);
p3 = state_space_plot(prStates_im_ls, probUpCrossing_im_ls, probDownCrossing_im_ls, 10, 0.1, likelihoodLims, prStateLims);
p4 = state_space_plot(prStates_im_ss, probUpCrossing_im_ss, probDownCrossing_im_ss, 10, 0.01, likelihoodLims, prStateLims);

plot_array = Any[];
push!(plot_array, p1);
push!(plot_array, p2);
push!(plot_array, p3);
push!(plot_array, p4);
plot(plot_array...)
```

[^1]: For a more detailed overview see *Shinn, M., Lam, N. H., & Murray, J. D. (2020). A flexible framework for simulating and fitting generalized drift-diffusion models. ELife, 9, e56938.*

[^2]: More specifically, the built-in functions provide use the Forward-Euler method to solve the FPE.  